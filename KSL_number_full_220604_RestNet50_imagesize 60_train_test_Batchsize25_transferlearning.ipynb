{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import data processing and visualisation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import image processing libraries\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "\n",
    "# import tensorflow and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본 Parameter 설정\n",
    "BATCHSIZE = 25\n",
    "imageSize = 60\n",
    "target_dims = (imageSize, imageSize, 3)\n",
    "num_classes = 11 #0~10까지 총 11개\n",
    "train_len = 1534 #총 파일 수\n",
    "\n",
    "train_dir = \"../input/full/\" #train 폴더 경로 지정(끝에 / 까지 쳐야함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm #진행상황바 표시해주는 패키지\n",
    "\n",
    "def get_data(folder, data_len): #data불러오는 함수\n",
    "    \n",
    "    X = np.empty((data_len, imageSize, imageSize, 3), dtype=np.float32)\n",
    "    y = np.empty((data_len,), dtype=np.int)\n",
    "    cnt = 0\n",
    "\n",
    "    for folderName in os.listdir(folder): #기존 ASL alphabet용 코드를 약간 변형시켜줌\n",
    "        if not folderName.startswith('.'):\n",
    "            if folderName in ['00']: #label이 0부터 시작하게 하려고 0 사진 다운 받아둠\n",
    "                label = 0\n",
    "            elif folderName in ['01']:\n",
    "                label = 1\n",
    "            elif folderName in ['02']:\n",
    "                label = 2\n",
    "            elif folderName in ['03']:\n",
    "                label = 3\n",
    "            elif folderName in ['04']:\n",
    "                label = 4\n",
    "            elif folderName in ['05']:\n",
    "                label = 5\n",
    "            elif folderName in ['06']:\n",
    "                label = 6\n",
    "            elif folderName in ['07']:\n",
    "                label = 7\n",
    "            elif folderName in ['08']:\n",
    "                label = 8\n",
    "            elif folderName in ['09']:\n",
    "                label = 9\n",
    "            elif folderName in ['10']:\n",
    "                label = 10\n",
    "            for image_filename in tqdm(os.listdir(folder + folderName)):\n",
    "              img_file = cv2.imread(folder + folderName + '/' + image_filename)\n",
    "              if img_file is not None:\n",
    "                img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3)) #image 사이즈 조정\n",
    "                img_arr = np.asarray(img_file)\n",
    "                \n",
    "                X[cnt] = img_arr\n",
    "                y[cnt] = label\n",
    "                cnt += 1\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_data(train_dir,train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle 파일 load\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"../pickle/X_train_220602_imagesize_60_full\",\"rb\") as file :\n",
    "    X_train=pickle.load(file)\n",
    "    \n",
    "with open(\"../pickle/y_train_220602_imagesize_60_full\",\"rb\") as file2 :\n",
    "    y_train=pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data 불러온 결과 shape출력(데이터수, imageSize, imageSize, 3) : get_data함수에서 설정해준 항목\n",
    "print(\"The shape of X_train is : \", X_train.shape)\n",
    "print(\"The shape of y_train is : \", y_train.shape)\n",
    "print(\"The shape of one image is : \", X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#혹시 몰라 나중에 쓸 수도 있어 pickle파일 만들어봄(건너뛰어도 무관)\n",
    "import pickle\n",
    "\n",
    "X_train_220602_imagesize_60_full=X_train\n",
    "y_train_220602_imagesize_60_full=y_train\n",
    "\n",
    "\n",
    "with open(\"../pickle/X_train_220602_imagesize_60_full\",\"wb\") as file :\n",
    "    pickle.dump(X_train_220602_imagesize_60_full,file)\n",
    "with open(\"../pickle/y_train_220602_imagesize_60_full\",\"wb\") as file :\n",
    "    pickle.dump(y_train_220602_imagesize_60_full,file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예시로 이미지 출력\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making copies of original data\n",
    "X_data = X_train\n",
    "y_data = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#있는 데이터로 train, test split해주는 함수, test_size에서 비율 조정 가능\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3,random_state=42,stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train,test split된 것 출력해서 확인\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_transfer_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=target_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_transfer_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping함수를 이용해서 patience수가 넘어가면 자동으로 Early Stopping되게 함\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_model_tr = Sequential([\n",
    "    ResNet_transfer_model, \n",
    "    Flatten(), \n",
    "    Dense(64, activation='relu'), \n",
    "    Dense(11, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling\n",
    "ResNet_model_tr.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model fitting\n",
    "ResNet_model_tr.fit(X_train, y_train,\n",
    "          epochs=100,\n",
    "          batch_size=BATCHSIZE,\n",
    "          verbose=2,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model metrics\n",
    "metrics = pd.DataFrame(VGG16_model_tr.history.history)\n",
    "print(\"The model metrics are\")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#저장된 accuracy 그래프로 출력\n",
    "metrics[['accuracy','val_accuracy']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#저장된 loss 그래프로 출력\n",
    "metrics[['loss','val_loss']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "ResNet_model_tr.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions=ResNet_model_tr.predict(X_test)\n",
    "predictions=y_predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix로 표시\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(confusion_matrix(y_test,predictions))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
